{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    def __init__(self, user_input):\n",
    "        self.user_input = user_input\n",
    "        self.data_recom = pd.DataFrame()\n",
    "\n",
    "    def clean_user_input(self):\n",
    "        # Descargar los recursos necesarios de la libreria NLTK\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "\n",
    "        # Convertir texto a minusculas\n",
    "        text = self.user_input.lower()\n",
    "\n",
    "        # Quitar puntuaci√≥n\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "        # Tokenizar el texto\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Quitar stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "        # Join the tokens back into a cleaned text\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "\n",
    "        return cleaned_text\n",
    "\n",
    "    def prepare_user_input(self):\n",
    "        cleaned_name = self.user_input.replace(\" \", \"-\").lower()\n",
    "        return cleaned_name\n",
    "\n",
    "    def scraping(self):\n",
    "\n",
    "        cleaned_text = self.clean_user_input()\n",
    "        prep_clean_text = self.prepare_user_input()\n",
    "        urls = ['https://listado.mercadolibre.com.ar/' + prep_clean_text]\n",
    "\n",
    "        page_number = 50\n",
    "        for i in range(0, 100, 50):\n",
    "            urls.append(f\"https://listado.mercadolibre.com.ar/{prep_clean_text}_Desde_{page_number + 1}_NoIndex_True\")\n",
    "            page_number += 50\n",
    "\n",
    "        # Lista para almacenar lo escrapeado\n",
    "        scraped_data = []\n",
    "\n",
    "        # Iterar URL\n",
    "        for i, url in enumerate(urls, start=1):\n",
    "            # Traer el HTML de la pagina\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # agarro los posteos\n",
    "            content = soup.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "            # sobre cada posteo se itera para traer el contenido\n",
    "            for post in content:\n",
    "                title = post.find('h2').text\n",
    "                price = post.find('span', class_='andes-money-amount__fraction').text\n",
    "                post_link = post.find(\"a\")[\"href\"]\n",
    "\n",
    "                try:\n",
    "                    brand = post.find('span', class_= 'ui-search-item__brand-discoverability ui-search-item__group__element').text\n",
    "                except:\n",
    "                    brand = '-'\n",
    "\n",
    "                try:\n",
    "                    img_link = post.find(\"img\")[\"data_recom-src\"]\n",
    "                except:\n",
    "                    img_link = post.find(\"img\")[\"src\"]\n",
    "\n",
    "                try:\n",
    "                    post_rvw = post.find(\"span\", class_='ui-search-reviews__rating-number').text\n",
    "                except:\n",
    "                    post_rvw = '0'\n",
    "\n",
    "                try:\n",
    "                    post_rvw_amount = post.find(\"span\", class_='ui-search-reviews__amount').text\n",
    "                except:\n",
    "                    post_rvw_amount = '-'\n",
    "\n",
    "                post_data = {\n",
    "                    \"title\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"price\": price,\n",
    "                    \"post link\": post_link,\n",
    "                    \"image link\": img_link,\n",
    "                    \"review\": float(post_rvw),\n",
    "                    \"review amount\": post_rvw_amount \n",
    "                }\n",
    "                scraped_data.append(post_data)\n",
    "\n",
    "        self.data_recom = pd.DataFrame(scraped_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
